{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI MLPs — Wine & Breast Cancer (PyTorch)\n",
    "This notebook reproduces the training with a compact configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from sklearn.datasets import load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, f1_score\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, out_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers=[]; prev=in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(prev,h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            prev=h\n",
    "        layers += [nn.Linear(prev,out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "def accuracy_from_logits(logits, y):\n",
    "    return (torch.argmax(logits,1)==y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_split(X, y):\n",
    "    X_trv, X_te, y_trv, y_te = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X_trv, y_trv, test_size=0.2, random_state=0, stratify=y_trv)\n",
    "    sc=StandardScaler(); X_tr=sc.fit_transform(X_tr); X_va=sc.transform(X_va); X_te=sc.transform(X_te)\n",
    "    return X_tr,y_tr,X_va,y_va,X_te,y_te\n",
    "\n",
    "def train_one(X_tr,y_tr,X_va,y_va,X_te,y_te,n_classes,tag='run'):\n",
    "    model=MLP(X_tr.shape[1],[64,32],n_classes,0.1)\n",
    "    opt=torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-4)\n",
    "    crit=nn.CrossEntropyLoss()\n",
    "    hist={'trL':[],'vaL':[],'trA':[],'vaA':[]}\n",
    "    patience=8; best=-1; wait=0\n",
    "    for ep in range(1,81):\n",
    "        model.train(); Ls=[]; As=[]\n",
    "        for i in range(0,len(X_tr),32):\n",
    "            xb=torch.tensor(X_tr[i:i+32],dtype=torch.float32)\n",
    "            yb=torch.tensor(y_tr[i:i+32],dtype=torch.long)\n",
    "            opt.zero_grad(); lg=model(xb); loss=crit(lg,yb); loss.backward(); opt.step()\n",
    "            Ls.append(loss.item()); As.append(accuracy_from_logits(lg,yb))\n",
    "        model.eval(); vLs=[]; vAs=[]; import numpy as np\n",
    "        with torch.no_grad():\n",
    "            for i in range(0,len(X_va),32):\n",
    "                xb=torch.tensor(X_va[i:i+32],dtype=torch.float32); yb=torch.tensor(y_va[i:i+32],dtype=torch.long)\n",
    "                lg=model(xb); vLs.append(crit(lg,yb).item()); vAs.append(accuracy_from_logits(lg,yb))\n",
    "        hist['trL'].append(np.mean(Ls)); hist['vaL'].append(np.mean(vLs)); hist['trA'].append(np.mean(As)); hist['vaA'].append(np.mean(vAs))\n",
    "        # early stop on macro F1\n",
    "        yvp=[]; yvt=[]\n",
    "        with torch.no_grad():\n",
    "            for i in range(0,len(X_va),32):\n",
    "                xb=torch.tensor(X_va[i:i+32],dtype=torch.float32); yb=torch.tensor(y_va[i:i+32],dtype=torch.long)\n",
    "                lg=model(xb); yvp.append(torch.argmax(lg,1).numpy()); yvt.append(yb.numpy())\n",
    "        import numpy as np\n",
    "        from sklearn.metrics import f1_score\n",
    "        f1=f1_score(np.concatenate(yvt), np.concatenate(yvp), average='macro', zero_division=0)\n",
    "        if f1>best+1e-6: best=f1; best_state={k:v.clone() for k,v in model.state_dict().items()}; wait=0\n",
    "        else:\n",
    "            wait+=1\n",
    "        if wait>=patience: break\n",
    "    model.load_state_dict(best_state)\n",
    "    # test metrics\n",
    "    yp=[]; yt=[]\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,len(X_te),32):\n",
    "            xb=torch.tensor(X_te[i:i+32],dtype=torch.float32); yb=torch.tensor(y_te[i:i+32],dtype=torch.long)\n",
    "            lg=model(xb); yp.append(torch.argmax(lg,1).numpy()); yt.append(yb.numpy())\n",
    "    import numpy as np\n",
    "    yp=np.concatenate(yp); yt=np.concatenate(yt)\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    acc=accuracy_score(yt,yp); pr,rc,f1,_=precision_recall_fscore_support(yt,yp,average='macro', zero_division=0)\n",
    "    return model,hist,{'accuracy':acc,'precision_macro':pr,'recall_macro':rc,'f1_macro':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on Wine\n",
    "wine=load_wine(); Xw=wine.data.astype('float32'); yw=wine.target.astype('int64')\n",
    "Xtr,ytr,Xva,yva,Xte,yte=standardize_split(Xw,yw)\n",
    "model_w,hist_w,met_w=train_one(Xtr,ytr,Xva,yva,Xte,yte,len(wine.target_names),'wine')\n",
    "met_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on Breast Cancer\n",
    "bc=load_breast_cancer(); Xb=bc.data.astype('float32'); yb=bc.target.astype('int64')\n",
    "Xtr,ytr,Xva,yva,Xte,yte=standardize_split(Xb,yb)\n",
    "model_b,hist_b,met_b=train_one(Xtr,ytr,Xva,yva,Xte,yte,len(bc.target_names),'breast_cancer')\n",
    "met_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting helpers\n",
    "The following cell plots training/validation loss and accuracy for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Wine plots\n",
    "plt.figure(); plt.plot(hist_w['trL'],label='Train Loss'); plt.plot(hist_w['vaL'],label='Val Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Wine — Loss'); plt.legend();\n",
    "plt.figure(); plt.plot(hist_w['trA'],label='Train Acc'); plt.plot(hist_w['vaA'],label='Val Acc'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Wine — Accuracy'); plt.legend();\n",
    "# Breast plots\n",
    "plt.figure(); plt.plot(hist_b['trL'],label='Train Loss'); plt.plot(hist_b['vaL'],label='Val Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Breast Cancer — Loss'); plt.legend();\n",
    "plt.figure(); plt.plot(hist_b['trA'],label='Train Acc'); plt.plot(hist_b['vaA'],label='Val Acc'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Breast Cancer — Accuracy'); plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
